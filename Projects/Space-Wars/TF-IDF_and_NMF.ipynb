{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 00: TF-IDF + NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# # Get a sorted list of the objects and their sizes\n",
    "# sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"Data/df.pkl\", 'rb') as picklefile:\n",
    "    df = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do our analysis on stemmed words so that same topic is not split (e.g. \"word\" and \"words\" should belong to the same topic):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from textblob import TextBlob\n",
    "# stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "# def stem_getter(text):\n",
    "#     return \" \".join([stemmer.stem(word) for word in TextBlob(text).words])\n",
    "\n",
    "# df.raw_text = df.raw_text.map(stem_getter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time around, let's remove words in all caps: they are used to indicate character lines. Using them will just create topics identifying major characters of a show/movie which is not helpful. Let's also remove non-letter characters along the way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cap_remover(text):\n",
    "    text = re.sub(r'[A-Z]+(?![a-z])', '', text)\n",
    "    text = re.sub(r'[\\d]+', '', text)\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    return re.sub(r\"[^\\w' ]\", '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.raw_text = df.raw_text.map(cap_remover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def stopword_remover(text):\n",
    "#     return \" \".join([word for word in text.lower().split() if word not in stoplist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df.raw_text = df.raw_text.map(stopword_remover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.raw_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleksod/anaconda/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['f']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "# Import all of the scikit learn stuff\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = df.raw_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have also used a large list of keywords from [here](http://www.ranks.nl/stopwords) and supplemented it with Star Trek specific terms discovered in the initial LDA model so that they are not used in topic analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Data/stopwords_wpropers.txt') as f:\n",
    "     content = (f.read()).split()#f.readlines()\n",
    "# for i in range(len(content)):\n",
    "#     content[i] = content[i].replace(\"\\n\", \"\").lower()\n",
    "stoplist = sorted(list(set(content)))\n",
    "# texts = [\" \".join([word for word in cluster_dict[i].lower().split() if word not in stoplist])\n",
    "#          for i in cluster_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = stoplist, ngram_range=(1, 3))\n",
    "dtm = vectorizer.fit_transform(docs) \n",
    "# pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names()).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's search for th optimal number of topics to explore (e.g. search until topics start make sense):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics for 10 topic NMF are:\n",
      "['core', 'three', 'doctor', 'lieutenant', 'astrometrics', 'commander', 'equinox', 'ensign', 'field', 'good', 'shuttle', 'people', 'course', 'find', 'help', 'temporal', 'power', 'warp', 'shields', 'crew', 'viewscreen', 'mister', 'well', 'engineering', 'sickbay', 'time', 'going', 'will', 'ship', 'bridge']\n",
      "['bar', 'sees', 'man', 'smile', 'long', 'doesn', 'hand', 'room', 'good', 'ship', 'head', 'suddenly', 'table', 'continuing', 'eyes', 'console', 'station', 'reacts', 'face', 'takes', 'door', 'nods', 'going', 'will', 'time', 'smiles', 'moment', 'turns', 'moves', 'beat']\n",
      "['aye sir', 'phasers', 'orbit', 'course', 'neutral', 'vessel', 'turns', 'man', 'command', 'beam', 'warp', 'phaser', 'well', 'time', 'commander', 'viewer', 'aye', 'transporter', 'lore', 'room', 'lieutenant', 'power', 'doctor', 'planet', 'continuing', 'ship', 'will', 'bridge', 'mister', 'sir']\n",
      "['room', 'didn', 'council', 'find', 'ships', 'plating', 'metres', 'will', 'well', 'porthos', 'command', 'high command', 'three', 'monitor', 'hull', 'people', 'launch', 'weapons', 'launch bay', 'earth', 'viewscreen', 'warp', 'weapon', 'time', 'armoury', 'going', 'shuttlepod', 'sir', 'bridge', 'ship']\n",
      "['lead alien', 'pursuit hunter', 'quadrant', 'hunters', 'helmet', 'combadge', 'rules', 'nodes', 'will', 'aliens', 'optical flash', 'uhhuh', 'security', 'ship', 'die honor', 'crossbow', 'moves', 'barkeep', 'captive pursuit captive', 'pursuit captive', 'pursuit captive pursuit', 'wormhole', 'reacts', 'hunt', 'alien', 'beat', 'hunter', 'pursuit', 'captive', 'captive pursuit']\n",
      "['gland', 'neuropressure', 'ointment', 'weapon', 'runs hands', 'fair price', 'bridge ahead', 'interested find', 'liquid form', 'met station', 'woman white', 'market', 'agree fair', 'agree fair price', 'confident agree', 'confident agree fair', 'market chemist', 'humans', 'species', 'liquid', 'synthesise', 'shop', 'barge', 'bioweapon', 'chemist shop', 'quarters', 'rat', 'barge twelve', 'brig', 'chemist']\n",
      "['minds', 'colt', 'life', 'surface', 'screen', 'earth', 'survivors encampment', 'primitive', 'mind', 'flash', 'rigel', 'laser', 'planet surface', 'commodore', 'zoo', 'read thoughts', 'keeper', 'mister', 'illusions', 'specimens', 'sir', 'read', 'magistrate', 'planet', 'survivors', 'thoughts', 'specimen', 'hearing room', 'cage', 'illusion']\n",
      "['astrometrics lab', 'mister', 'help', 'simulation', 'crew', 'lieutenant', 'good', 'pathfinder lab', 'astrometrics', 'er', 'ship', 'moriarty', 'subroutines', 'medical', 'will', 'pathfinder', 'time', 'lab', 'going', 'holographic', 'computer', 'sickbay', 'zimmerman', 'well', 'reg', 'hologram', 'dont', 'doctor', 'holodeck', 'programme']\n",
      "['works', 'relics', 'commander', 'outpost', 'sir', 'gambit gambit', 'gambit cont', 'barradas three', 'calder', 'moves', 'barradas', 'continuing', 'giusti', 'ship', 'mercenaries', 'artifact', 'mercenary ship', 'resonator', 'artifacts', 'koral', 'console', 'galen', 'vekor', 'mercenary', 'yranac', 'beat', 'narik', 'tallera', 'gambit', 'baran']\n",
      "['time', 'technology', 'raven', 'node', 'axum', 'sickbay', 'maturation', 'vinculum', 'bay', 'cargo', 'assimilation', 'irrelevant', 'bridge', 'korok', 'vessel', 'assimilate', 'chamber', 'cargo bay', 'sphere', 'transwarp', 'queen', 'queen chamber', 'nanoprobes', 'will', 'assimilated', 'drone', 'drones', 'unimatrix', 'cube', 'collective']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num_topics in range(10,11):\n",
    "    nmf_model = NMF(num_topics)\n",
    "\n",
    "    dtm_nmf = nmf_model.fit_transform(dtm)\n",
    "\n",
    "    # use NMF to attempt Topic Modeling\n",
    "    words = vectorizer.get_feature_names()\n",
    "\n",
    "    # get num_topic_words top topic words:\n",
    "    num_topic_words = 30\n",
    "\n",
    "    # iterate through our eigenvectors\n",
    "    print(\"The topics for {} topic NMF are:\".format(num_topics))\n",
    "    for r in nmf_model.components_:\n",
    "        # sort values associated with each dimension \n",
    "        a=sorted([(v,i) for i,v in enumerate(r)])[-num_topic_words:]\n",
    "        # map back to words\n",
    "        print([words[i[1]] for i in a])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like having # topics in NMF model makes the most sense to me. The as far as I can tell are topics:\n",
    "1. \n",
    "2. \n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf_model = NMF(15)\n",
    "\n",
    "dtm_nmf = nmf_model.fit_transform(dtm)\n",
    "# dtm_nmf = Normalizer(copy=False).fit_transform(dtm_nmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(678, 49838)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 678 documents and the matrix has thousands and thousands of words associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.13,  0.01,  0.  ,  0.  ],\n",
       "       [ 0.03,  0.18,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.02,  0.13,  0.  ,  0.  ,  0.  ],\n",
       "       ..., \n",
       "       [ 0.01,  0.12,  0.07,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.15,  0.03,  0.  ,  0.  ],\n",
       "       [ 0.01,  0.12,  0.04,  0.  ,  0.  ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_nmf[:,:5].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.01,  0.  ,  0.  ,  0.  ,  0.07],\n",
       "       ..., \n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.01]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_nmf[:,5:10].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the NMF-transformed TF-IDF matrices above, there are no strong topics emerging out of the 10 columns. Therefore, I shall attempt to perform K-means clustering to classify the documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(678, 10)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_nmf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we have two topics now (two columns in the NMF transformed matrix). And the components (word distribution among the two topics) of those two topics are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.33850614e-03,   0.00000000e+00,   4.53588539e-05, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.94387040e-05],\n",
       "       [  0.00000000e+00,   3.36421378e-04,   3.55596430e-04, ...,\n",
       "          0.00000000e+00,   1.68352417e-05,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   2.67690335e-05,   2.80993368e-05, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.42787006e-04],\n",
       "       ..., \n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model.components_ #[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 49838)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just assign each document to its highest feature, a clustering, in a sense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nmf_data_clust=[list(in_list).index(max(in_list)) for in_list in dtm_nmf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "678"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nmf_data_clust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['doctor', 'programme', 'will', 'sickbay', 'going', 'ship', 'bridge']\n",
      "['sir', 'time', 'will', 'turns', 'moves', 'continuing', 'beat']\n",
      "['cube', 'will', 'descent', 'collective', 'borg ship', 'hugh', 'borg']\n",
      "['martok', 'damar', 'weyoun', 'dominion', 'jem', 'hadar', 'jem hadar']\n",
      "['lwaxana', 'shattered mirror', 'explorers', 'visitor', 'muse', 'beat', 'jake']\n",
      "['weyoun', 'afterimage', 'penumbra', 'winn', 'damar', 'vic', 'ezri']\n",
      "['shran', 'sir', 'degra', 'vulcan', 'xindi', 'bridge', 'ship']\n",
      "['du', 'brunt', 'maihar', 'maihar du', 'ferengi', 'zek', 'nagus']\n",
      "['ship', 'planet', 'will', 'bridge', 'scott', 'mister', 'sir']\n",
      "['duras', 'redemption', 'kor', 'martok', 'kurn', 'klingon', 'gowron']\n",
      "['kalita', 'rascals', 'preemptive', 'conundrum', 'preemptive strike', 'ensign ro', 'ro']\n",
      "['alien', 'beat', 'hunter', 'pursuit', 'captive', 'captive pursuit', 'tosk']\n",
      "['bajoran', 'resurrection', 'collaborator', 'prophets', 'vedek', 'winn', 'bareil']\n",
      "['blaze', 'jennifer', 'cardassians', 'hudson', 'cardassian', 'maquis', 'eddington']\n",
      "['barge twelve', 'reptilian', 'brig', 'chemist', 'trellium', 'xindi', 'rajiin']\n"
     ]
    }
   ],
   "source": [
    "# 4) use NMF to attempt Topic Modeling\n",
    "words = vectorizer.get_feature_names()\n",
    "\n",
    "## get 7 top topic words:\n",
    "\n",
    "# iterate through our eigenvectors\n",
    "for r in nmf_model.components_:\n",
    "    # sort values associated with each dimension \n",
    "    a=sorted([(v,i) for i,v in enumerate(r)])[-30:]\n",
    "    # map back to words\n",
    "    print([words[i[1]] for i in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mess hall', 'course', 'find', 'warp', 'shields', 'lieutenant', 'people', 'lab', 'viewscreen', 'good', 'help', 'computer', 'mister', 'astrometrics', 'crew', 'engineering', 'kazon', 'delta', 'delta flyer', 'holodeck', 'well', 'flyer', 'time', 'doctor', 'programme', 'will', 'sickbay', 'going', 'ship', 'bridge']\n",
      "['panel', 'station', 'long', 'man', 'hand', 'table', 'doctor', 'computer', 'head', 'suddenly', 'room', 'commander', 'going', 'takes', 'eyes', 'face', 'ship', 'door', 'nods', 'smiles', 'moment', 'console', 'reacts', 'sir', 'time', 'will', 'turns', 'moves', 'continuing', 'beat']\n",
      "['bridge', 'borg cube', 'ruby', 'borg queen chamber', 'queen chamber', 'locutus', 'vessel', 'sphere', 'assimilate', 'icheb', 'queen', 'transwarp', 'borg queen', 'best worlds', 'nanoprobes', 'ship', 'unimatrix', 'worlds', 'lore', 'drones', 'drone', 'shelby', 'assimilated', 'cube', 'will', 'descent', 'collective', 'borg ship', 'hugh', 'borg']\n",
      "['shoals', 'rocks shoals', 'call arms', 'female', 'purgatory', 'vorta', 'soldiers', 'eris', 'treachery', 'inferno', 'runabout', 'siege', 'founders', 'ship', 'inferno light', 'time stand', 'iklan', 'omet', 'omet iklan', 'beat', 'shapeshifter', 'muniz', 'female shapeshifter', 'martok', 'damar', 'weyoun', 'dominion', 'jem', 'hadar', 'jem hadar']\n",
      "['bajoran', 'onaya', 'moment', 'civil defense', 'leyton', 'time', 'shattered', 'reckoning', 'melanie', 'homefront', 'watters', 'emissary', 'ascent', 'smiles', 'dad', 'joseph', 'father', 'cards', 'going', 'valiant', 'jennifer', 'kirby', 'giger', 'lwaxana', 'shattered mirror', 'explorers', 'visitor', 'muse', 'beat', 'jake']\n",
      "['changing', 'dominion', 'ross', 'gor', 'yanas', 'thot gor', 'frankie', 'going', 'thot', 'baddabing', 'ilario', 'norvo', 'prophets', 'janel', 'emperor', 'jadzia', 'prodigal', 'beat', 'solbor', 'joran', 'field fire', 'breen', 'kasidy', 'weyoun', 'afterimage', 'penumbra', 'winn', 'damar', 'vic', 'ezri']\n",
      "['andorian', 'hull', 'ships', 'three', 'launch', 'reptilian', 'command', 'will', 'andorians', 'launch bay', 'people', 'high command', 'weapons', 'earth', 'warp', 'viewscreen', 'weapon', 'armoury', 'vulcans', 'suliban', 'time', 'shuttlepod', 'going', 'shran', 'sir', 'degra', 'vulcan', 'xindi', 'bridge', 'ship']\n",
      "['ferenginar', 'body parts', 'magnificent ferengi', 'rules', 'family business', 'latinum', 'motive', 'grand', 'leeta', 'krax', 'acquisition', 'prophet', 'pel', 'bar', 'rules acquisition', 'brother', 'grand nagus', 'prophet motive', 'nilva', 'moogie', 'ishka', 'ferengi love', 'profit', 'du', 'brunt', 'maihar', 'maihar du', 'ferengi', 'zek', 'nagus']\n",
      "['vessel', 'creature', 'mudd', 'men', 'course', 'commodore', 'earth', 'yeoman', 'phaser', 'transporter room', 'surface', 'time', 'planet surface', 'man', 'aye', 'lieutenant', 'transporter', 'room', 'well', 'power', 'mister scott', 'doctor', 'pike', 'ship', 'planet', 'will', 'bridge', 'scott', 'mister', 'sir']\n",
      "['sins', 'bat', 'bat leth', 'father', 'leth', 'sons mogh', 'etor', 'toral', 'sins father', 'mpec', 'grilka', 'sons', 'mogh', 'empire', 'sword', 'apocalypse', 'kahless', 'council', 'ehleyr', 'will', 'warrior', 'klingons', 'beat', 'duras', 'redemption', 'kor', 'martok', 'kurn', 'klingon', 'gowron']\n",
      "['cardassians', 'cardassian', 'laren', 'romulan', 'maquis', 'chroniton', 'ship', 'orta', 'kennelly', 'young ro', 'santos', 'parem', 'console', 'young', 'strike', 'brossmer', 'macias', 'phase', 'power play', 'mirok', 'ensign', 'macduff', 'beat', 'kalita', 'rascals', 'preemptive', 'conundrum', 'preemptive strike', 'ensign ro', 'ro']\n",
      "['rules', 'will', 'aliens', 'optical flash', 'uhhuh', 'beat tosk', 'coladrium', 'ship', 'security', 'moves', 'die honor', 'crossbow', 'barkeep', 'arva', 'arva nodes', 'captive pursuit captive', 'pursuit captive', 'pursuit captive pursuit', 'tosk captive', 'tosk captive pursuit', 'wormhole', 'reacts', 'hunt', 'alien', 'beat', 'hunter', 'pursuit', 'captive', 'captive pursuit', 'tosk']\n",
      "['life', 'cardassian', 'promenade', 'cardassians', 'reckoning', 'vedek winn', 'nerys', 'support', 'orb', 'vedek bareil', 'major', 'bek', 'life support', 'fascination', 'emissary', 'circle', 'li', 'neela', 'kubus', 'beat', 'bajor', 'kai', 'shakaar', 'bajoran', 'resurrection', 'collaborator', 'prophets', 'vedek', 'winn', 'bareil']\n",
      "['going', 'major', 'glass', 'cardassia', 'die cast', 'station', 'gul', 'central command', 'amaros', 'changeling', 'ship', 'ziyal', 'kazon', 'demilitarized zone', 'demilitarized', 'federation', 'uniform', 'badlands', 'xhosa', 'adversary', 'sakonna', 'beat', 'kasidy', 'blaze', 'jennifer', 'cardassians', 'hudson', 'cardassian', 'maquis', 'eddington']\n",
      "['liquid trellium', 'market chemist', 'met deuterium', 'met deuterium station', 'oran', 'oran taku', 'rat ud', 'synthesise trellium', 'taku', 'trellium extremely', 'zjod', 'humans', 'weapon', 'liquid', 'species', 'synthesise', 'shop', 'barge', 'bioweapon', 'quarters', 'chemist shop', 'degra', 'rat', 'barge twelve', 'reptilian', 'brig', 'chemist', 'trellium', 'xindi', 'rajiin']\n"
     ]
    }
   ],
   "source": [
    "# iterate through our eigenvectors\n",
    "for r in nmf_model.components_:\n",
    "    # sort values associated with each dimension \n",
    "    a=sorted([(v,i) for i,v in enumerate(r)])[-30:]\n",
    "    # map back to words\n",
    "    print([words[i[1]] for i in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
